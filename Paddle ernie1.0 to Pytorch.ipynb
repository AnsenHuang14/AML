{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://github.com/nghuyong/ERNIE-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import paddle.fluid.dygraph as D\n",
    "from ernie.tokenizing_ernie import ErnieTokenizer\n",
    "from ernie.modeling_ernie import ErnieModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert paddle ernie 1.0 to pytorch \n",
    "Make sure output are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paddle version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 18:57:00,662-INFO: pretrain dir ./model-ernie1.0.1 not in {'ernie-1.0': 'https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz', 'ernie-2.0-en': 'https://ernie-github.cdn.bcebos.com/model-ernie2.0-en.1.tar.gz', 'ernie-2.0-large-en': 'https://ernie-github.cdn.bcebos.com/model-ernie2.0-large-en.1.tar.gz', 'ernie-tiny': 'https://ernie-github.cdn.bcebos.com/model-ernie_tiny.1.tar.gz'}, read from local\n",
      "2020-07-20 18:57:04,135-INFO: loading pretrained model from ./model-ernie1.0.1\n",
      "/Users/ansenhuang/opt/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:718: UserWarning: Varibale [ mlm_bias mlm.weight mlm.bias mlm_ln.weight mlm_ln.bias ] are not used, because not included in layers state_dict\n",
      "  format(\" \".join(unused_para_list)))\n",
      "2020-07-20 18:57:07,792-INFO: pretrain dir ./model-ernie1.0.1 not in {'ernie-1.0': 'https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz', 'ernie-2.0-en': 'https://ernie-github.cdn.bcebos.com/model-ernie2.0-en.1.tar.gz', 'ernie-2.0-large-en': 'https://ernie-github.cdn.bcebos.com/model-ernie2.0-large-en.1.tar.gz', 'ernie-tiny': 'https://ernie-github.cdn.bcebos.com/model-ernie_tiny.1.tar.gz', 'ernie-gen-base-en': 'https://ernie-github.cdn.bcebos.com/model-ernie-gen-base-en.1.tar.gz', 'ernie-gen-large-en': 'https://ernie-github.cdn.bcebos.com/model-ernie-gen-large-en.1.tar.gz'}, read from local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.          0.99479663 -0.99986964 -0.7872066  -1.\n",
      "  -0.99919444  0.985997   -0.22648102  0.97202295 -0.9994965  -0.982234\n",
      "  -0.6821966  -0.9998574  -0.83046496 -0.9804977  -1.          0.9999509\n",
      "  -0.55144966  0.48973152 -1.          1.          0.14248642 -0.71969527\n",
      "  -0.9055147   0.97965705 -0.999682    0.85135585  1.         -0.39387462\n",
      "  -0.99999905  0.9999919  -0.9992018  -0.09899261  0.99996     0.7490412\n",
      "  -0.9999922  -0.9657562  -0.9960676  -0.95335084  0.9999292  -0.9197153\n",
      "  -0.99989647  0.63038546 -0.9860959  -0.99991727 -1.          0.99999994\n",
      "  -0.99999994 -0.82624584 -0.9744699   0.99909854  1.         -0.9999999\n",
      "  -0.9999997  -0.999507   -0.02157898 -1.          0.99975914  0.9932416\n",
      "  -0.99919933 -1.          1.          0.39329714 -0.31263566 -0.9984498\n",
      "  -0.9835464  -0.9999865  -0.98631394  0.99999607  0.98583347 -0.99960685\n",
      "  -0.9474886  -0.99999726  1.         -0.9858534   0.688139    1.\n",
      "   0.99902004  0.9886897   1.          0.99939877 -0.99691194  0.9998407\n",
      "   1.         -1.         -0.999989    0.9622676   1.         -0.9073396\n",
      "  -0.9999989   0.41061106  0.35902512  0.97015893  1.         -1.\n",
      "   0.99992687 -0.0964089   0.99978644  1.         -0.530104    0.9979866\n",
      "  -0.9999991   0.99999976 -0.569061   -1.          1.         -1.\n",
      "  -0.8341091  -0.9972185   0.7137046   0.6173493   0.99986655  1.\n",
      "   1.         -0.99914074 -0.9982252  -0.29370782  0.9498659   0.974079\n",
      "  -0.97978586  0.9999881  -0.9997873   0.89261305 -0.999963    0.9875354\n",
      "   0.9999668  -0.9995632  -0.7013648   0.9091246   0.9999299   0.36666223\n",
      "  -0.99957234 -0.9999999   0.99990904  0.9999945   0.9999999  -0.9953213\n",
      "   1.          0.9722779   1.          0.9999953  -0.7862495   0.9995345\n",
      "   0.8351892   0.9918631   0.9650966  -0.99940604 -0.9712901  -0.99475235\n",
      "   0.9923304   0.9999903   0.8533538  -0.9400228  -0.9748845   1.\n",
      "   1.         -1.          0.9351647   0.9987284   1.          0.999715\n",
      "  -0.9965259  -0.54677594  1.          0.99421793  0.60691833 -1.\n",
      "   0.9966893  -0.94738007 -0.99999994  0.9986268   0.999989    1.\n",
      "  -1.         -0.527316    0.04165652  0.9937646   0.88374025 -1.\n",
      "  -0.9889255   1.          0.99999416 -1.         -0.73221725  0.8570928\n",
      "  -0.999245    0.35026038  0.98152554 -0.99999976  0.7171257   0.97186583\n",
      "  -0.9991775   0.9970284  -0.9999528  -0.7097994  -0.999998   -0.96868265\n",
      "  -0.3610324  -0.9055083   0.9993948  -0.49309695  0.99990445 -0.9978073\n",
      "   0.7300043   0.9939311  -0.98935276 -0.9945301   0.99832517 -0.97943145\n",
      "   0.53081536 -0.99797535 -0.95295066  0.99999845 -0.99999976 -0.7356121\n",
      "   0.8141547   1.          0.9892449  -0.8346806  -1.          0.9997429\n",
      "  -0.8681047  -0.9997559  -0.20181328 -0.9999955  -0.9999992  -0.21824215\n",
      "   0.9998733   1.          0.9999924  -0.99840605  0.9407251   0.4017578\n",
      "  -0.9992026  -0.82429636 -0.942953    0.99978983  0.7694285   0.9777225\n",
      "   0.99998903 -1.          0.8595468   0.99960047 -0.99676716 -0.999433\n",
      "  -0.999798    0.99998605  0.9996594  -0.9996685  -0.96993804  0.7935618\n",
      "  -0.45320496  0.9830855  -0.5497208   0.99300534  0.99988496  1.\n",
      "  -0.9999993  -1.         -0.99618727  0.2331469  -0.99719536 -0.806616\n",
      "   0.32800168  1.          0.9999986  -0.9734314  -1.          0.9978575\n",
      "  -0.9919796   0.99999815 -1.         -0.13344261  1.         -0.9996104\n",
      "   0.997187   -0.9864563   0.16868863 -0.99276286  0.9999972   0.9200264\n",
      "  -0.9242952  -0.9999326   0.9988716  -0.97259337 -1.         -1.\n",
      "  -1.          0.99693316  0.9999597   0.9950433   0.8853865   0.9835156\n",
      "   0.9997289   0.99856824 -0.9649252  -0.9971054  -1.         -1.\n",
      "  -0.8998267  -0.9311264  -0.97404075  0.2537211  -1.         -0.9191791\n",
      "  -0.999935    0.9993159   1.         -1.          0.02620407 -0.99809736\n",
      "   0.99772954  1.         -1.          0.9999909   0.992443    0.9997116\n",
      "  -1.          0.9988211  -0.50127405  1.         -0.98255926 -0.8043855\n",
      "   0.99980813 -0.62940586 -0.9998867  -0.9706199   0.9978045  -0.6076609\n",
      "  -1.          1.         -0.9982328   0.99958396 -0.86450344 -0.76214844\n",
      "  -0.9998825   0.9517749  -0.8212135   0.29458448 -0.9982294   1.\n",
      "   1.          0.9689296   0.9927623  -0.9999997  -0.999273    1.\n",
      "  -0.99918365  0.81404096  0.6913403   0.93894166 -0.80623263  0.9999998\n",
      "   0.94318366 -0.9999073   0.98991054 -0.96207523 -0.20486738 -0.9984225\n",
      "  -0.39250657 -0.99386454  0.19342794  0.997843    0.9914832   1.\n",
      "   1.         -0.9217593  -1.          0.777627    0.92064124 -1.\n",
      "  -0.99893475 -0.46215075  0.9996879   0.80873096 -0.20582005  0.8834874\n",
      "   0.99975884  0.99866796 -0.9922761  -0.99996084  0.9998694  -0.82793516\n",
      "  -0.9984104  -0.9990964   0.9821191   1.         -0.9999998   0.9961604\n",
      "   0.99999976 -0.9999925  -0.9999998  -0.99999714  1.          0.99393135\n",
      "   0.9915205   0.99771667 -0.9999975   1.          0.98841125 -1.\n",
      "  -1.0000001   0.9928691   0.73384243 -1.         -0.9997164  -0.9977229\n",
      "   1.          0.9964063  -0.9999788   0.9579225   0.9986261  -0.9591689\n",
      "  -0.9325816   1.          0.9999817  -0.99965525 -0.05712062  0.79292655\n",
      "   1.         -1.         -0.63294464  0.999999    0.99999285 -0.9138506\n",
      "  -0.5814281  -0.99999756 -0.5022545  -0.9884215   0.62459964  0.99521846\n",
      "  -0.9662706   0.99879575  0.9193486   0.8657088  -0.7023969   0.99981546\n",
      "   1.          0.93622845  0.88115585 -0.8053172  -0.5261445   0.9999964\n",
      "   0.715626    0.6508105  -1.          0.9999997   0.97201794  0.08372381\n",
      "  -0.9537236  -0.98426497  0.80216944 -0.99989307  0.13942847  0.9476907\n",
      "   0.33132333  0.9190517  -0.64562154 -0.99998987  1.          1.\n",
      "   0.99966234  1.          0.980936    0.95855546 -0.99999714 -0.9999968\n",
      "  -0.77135634 -0.3200992  -1.         -0.8165568  -0.9010419  -0.91434294\n",
      "   0.9901419  -0.99999976  0.9999962  -0.9999999  -0.99835294 -0.7945876\n",
      "  -1.          0.9976138  -0.99917233  0.9999998   0.9976408  -0.9043437\n",
      "  -0.7195391   0.39754698  0.9692617   0.99999946  0.7809398   0.99996823\n",
      "   0.20420422  0.9471513   1.         -0.93191314 -0.99999994  0.9995098\n",
      "   0.04715961 -0.99948186 -0.42997736  1.          0.99354094 -0.92046833\n",
      "  -1.         -0.999862    0.94526565 -1.         -0.93060166 -0.9613411\n",
      "   0.92313194 -1.          0.9980211  -1.         -0.96500164 -0.999843\n",
      "   0.9979359   0.99998164 -1.          1.          0.99999267 -0.6386361\n",
      "   0.9985997  -0.99998957  0.9899823   0.9999999  -0.99988794 -0.99999815\n",
      "  -0.8187792   0.96947473 -0.99999994 -0.99999005 -0.9998917  -0.99973357\n",
      "   0.7184288  -0.9999977  -0.9999689  -0.24213035 -0.9999994   0.8264486\n",
      "   1.          0.9999992  -0.99702954  0.99994653  0.44653425  0.9999995\n",
      "   0.9047353   0.9982966   0.562305    1.         -1.         -0.9999001\n",
      "   0.9843749  -1.         -0.99825895  1.         -0.99998605 -0.9999753\n",
      "   0.9998784   1.         -0.9999597   0.94500023 -0.23792751 -0.8770328\n",
      "  -1.         -0.98388237 -0.99546325 -1.          0.952634   -0.9994246\n",
      "  -0.9998663  -0.9999824   0.9992353   0.995237    0.7922422   0.893773\n",
      "  -0.9999905  -0.99992734  0.96328115  0.9943541   0.9941962  -0.9999979\n",
      "   1.         -0.99741834  0.99996305 -0.29181513  0.9977631   0.98274726\n",
      "   0.9976778   1.          0.90089697  0.26522997 -0.99365455  1.\n",
      "  -0.9140641  -1.          0.98997015 -0.99999994 -1.          0.98956054\n",
      "   0.98788255  0.99736536 -0.99629045 -0.99829906  0.17212166 -0.9996059\n",
      "   0.0579397  -1.          0.9999997   0.9912049  -1.         -0.9885665\n",
      "  -0.9902784  -0.7572869   0.99752456 -0.17518866 -0.9912978  -0.99999326\n",
      "   0.99997234 -0.99999934 -0.8279126   0.98660254  0.99603254 -0.6756357\n",
      "  -0.7336667   1.          1.         -0.9998628   0.8316436  -0.36662844\n",
      "   0.6111804   0.9988031   0.9810423  -0.9588541   0.9994683   0.99999875\n",
      "  -0.9996056   0.9680579   0.10139739 -1.         -0.99993306  0.56645495\n",
      "   0.99999994 -0.9979601  -0.9999975   0.9998277  -0.999281   -0.99696416\n",
      "   0.99998325 -0.9999965   1.          1.         -0.9471592  -0.99986416\n",
      "   0.99730974  1.          0.9552294   0.9998091   0.99668235  0.99999964\n",
      "   1.         -0.9913356  -0.9999403   1.          0.92216367  0.99584055\n",
      "   0.98467463 -0.9994917   0.94751537  0.99999064  0.9875233   0.999985\n",
      "  -0.99707204 -1.          0.06024247  0.91710323 -0.99998903  1.\n",
      "   0.9999999  -0.7093202   0.99872446  0.9995061   0.32136896  0.9317001\n",
      "   1.         -0.9996941   0.9998096  -0.9960457   0.91744417  0.9999964\n",
      "   0.999698   -0.98548484 -0.9975593   0.88404953 -0.9254098  -0.9993419\n",
      "  -0.81233263  0.90769243 -0.9911981   0.50136054  0.99026996 -0.9805376\n",
      "  -0.9999451   0.9848072   0.38554856 -0.55921793  0.99018514  0.8039647\n",
      "   1.         -1.         -0.999719    0.8011266   0.67730385  0.99545497\n",
      "   0.9999696   0.9993313   0.00101653 -0.99999917  0.996108   -0.99704945\n",
      "   0.99996704 -0.9999998  -1.          0.9997395   0.98511857  0.99999493\n",
      "   1.          0.9961428   0.9999974   0.9982907  -0.79178387  0.99584574\n",
      "  -0.99146515 -1.          0.99999976  1.          0.99999505  0.14218065\n",
      "   0.99049294 -1.         -0.99067855  0.99999744 -0.9953327   0.98921716\n",
      "   0.93848914  0.8418771   1.          0.99999803  0.9800671   0.99886674\n",
      "   0.9999988   0.99946415  0.9849099   0.9996924  -0.79442227 -0.9999412\n",
      "   0.99827075  1.         -0.05767363  0.99999857  0.8176171   0.7983498\n",
      "  -0.14292054  1.         -0.99759513 -0.9999982  -0.99973375 -0.9993742 ]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "import numpy as np\n",
    "import paddle.fluid.dygraph as D\n",
    "from ernie.tokenizing_ernie import ErnieTokenizer\n",
    "from ernie.modeling_ernie import ErnieModel\n",
    "\n",
    "D.guard().__enter__() # activate paddle `dygrpah` mode\n",
    "\n",
    "model = ErnieModel.from_pretrained('./model-ernie1.0.1')    # Try to get pretrained model from server, make sure you have network connection\n",
    "model.eval()\n",
    "tokenizer = ErnieTokenizer.from_pretrained('./model-ernie1.0.1')\n",
    "\n",
    "ids, _ = tokenizer.encode('hello world')\n",
    "ids = D.to_variable(np.expand_dims(ids, 0))  # insert extra `batch` dimension\n",
    "pooled, encoded = model(ids)                 # eager execution\n",
    "print(pooled.numpy())                        # convert  results to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 18:57:14,776-INFO: Model name './convert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming './convert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-07-20 18:57:14,778-INFO: Didn't find file ./convert/added_tokens.json. We won't load it.\n",
      "2020-07-20 18:57:14,780-INFO: Didn't find file ./convert/special_tokens_map.json. We won't load it.\n",
      "2020-07-20 18:57:14,780-INFO: Didn't find file ./convert/tokenizer_config.json. We won't load it.\n",
      "2020-07-20 18:57:14,782-INFO: Didn't find file ./convert/tokenizer.json. We won't load it.\n",
      "2020-07-20 18:57:14,782-INFO: loading file ./convert/vocab.txt\n",
      "2020-07-20 18:57:14,783-INFO: loading file None\n",
      "2020-07-20 18:57:14,784-INFO: loading file None\n",
      "2020-07-20 18:57:14,785-INFO: loading file None\n",
      "2020-07-20 18:57:14,786-INFO: loading file None\n",
      "2020-07-20 18:57:14,808-INFO: loading configuration file ./convert/config.json\n",
      "2020-07-20 18:57:14,809-INFO: Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 513,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 18000\n",
      "}\n",
      "\n",
      "2020-07-20 18:57:14,810-INFO: loading weights file ./convert/pytorch_model.bin\n",
      "2020-07-20 18:57:16,502-INFO: All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "2020-07-20 18:57:16,502-INFO: All the weights of BertModel were initialized from the model checkpoint at ./convert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.          0.99479663 -0.99986964 -0.787209   -1.\n",
      "  -0.99919456  0.98599714 -0.22648044  0.97202307 -0.9994966  -0.9822342\n",
      "  -0.68219584 -0.9998575  -0.8304648  -0.98049814 -1.          0.99995095\n",
      "  -0.55145025  0.48973    -1.          1.          0.14248784 -0.7196955\n",
      "  -0.9055155   0.9796571  -0.999682    0.8513555   1.         -0.39387503\n",
      "  -0.9999991   0.99999195 -0.99920195 -0.09898911  0.9999599   0.74904054\n",
      "  -0.99999213 -0.96575624 -0.99606776 -0.95335126  0.9999292  -0.9197161\n",
      "  -0.99989647  0.6303841  -0.986096   -0.9999173  -1.          0.9999998\n",
      "  -1.         -0.8262469  -0.97447     0.9990984   1.         -0.99999976\n",
      "  -0.9999996  -0.99950695 -0.02157815 -1.          0.9997592   0.99324155\n",
      "  -0.9991993  -1.          0.99999994  0.3932952  -0.31263566 -0.9984498\n",
      "  -0.98354656 -0.99998647 -0.98631394  0.9999959   0.9858336  -0.9996068\n",
      "  -0.94748807 -0.99999726  1.         -0.98585314  0.6881363   1.\n",
      "   0.99902004  0.9886897   1.          0.9993987  -0.99691194  0.9998406\n",
      "   1.         -1.         -0.99998885  0.962268    1.         -0.90734076\n",
      "  -0.99999887  0.41061196  0.35902536  0.97015893  1.         -1.\n",
      "   0.99992687 -0.09640802  0.9997865   1.         -0.5301071   0.9979866\n",
      "  -0.9999991   0.9999998  -0.56906223 -1.          1.         -1.\n",
      "  -0.83410984 -0.9972185   0.71370685  0.6173519   0.99986655  1.\n",
      "   1.         -0.9991407  -0.9982252  -0.2937086   0.9498664   0.9740794\n",
      "  -0.9797861   0.9999882  -0.9997873   0.8926132  -0.999963    0.9875356\n",
      "   0.99996686 -0.99956316 -0.70136505  0.90912473  0.99992985  0.36666235\n",
      "  -0.99957246 -0.99999994  0.999909    0.99999446  0.99999976 -0.9953213\n",
      "   0.99999994  0.97227806  1.          0.9999953  -0.78624725  0.99953455\n",
      "   0.8351901   0.99186313  0.96509695 -0.99940604 -0.9712905  -0.99475235\n",
      "   0.9923305   0.99999034  0.85335463 -0.9400231  -0.9748847   1.\n",
      "   1.         -1.          0.93516403  0.9987283   1.          0.99971515\n",
      "  -0.99652594 -0.5467727   1.          0.9942181   0.60692066 -1.\n",
      "   0.9966893  -0.9473797  -1.          0.99862695  0.9999889   1.\n",
      "  -1.         -0.52731633  0.04165686  0.9937646   0.8837404  -1.\n",
      "  -0.98892546  1.          0.9999941  -1.         -0.73221827  0.8570936\n",
      "  -0.99924487  0.35025868  0.9815256  -0.9999997   0.7171253   0.97186595\n",
      "  -0.9991775   0.99702847 -0.99995285 -0.7098003  -0.99999785 -0.9686826\n",
      "  -0.36103654 -0.9055092   0.99939483 -0.49310082  0.99990445 -0.9978074\n",
      "   0.7300055   0.9939311  -0.98935264 -0.99453     0.9983252  -0.9794314\n",
      "   0.5308177  -0.9979754  -0.95295095  0.9999984  -0.9999998  -0.73561066\n",
      "   0.8141568   1.          0.98924494 -0.83468044 -1.          0.999743\n",
      "  -0.8681048  -0.9997558  -0.20181066 -0.99999547 -0.99999934 -0.21824062\n",
      "   0.9998732   1.          0.9999923  -0.99840605  0.9407253   0.401758\n",
      "  -0.9992026  -0.82429665 -0.9429532   0.9997898   0.7694289   0.9777228\n",
      "   0.99998903 -1.          0.8595478   0.99960047 -0.9967672  -0.9994331\n",
      "  -0.9997981   0.99998605  0.99965954 -0.99966854 -0.9699384   0.793561\n",
      "  -0.45320827  0.98308575 -0.5497228   0.99300534  0.99988496  1.\n",
      "  -0.9999992  -1.         -0.99618727  0.2331439  -0.99719536 -0.80661565\n",
      "   0.3279992   1.          0.99999857 -0.9734318  -1.          0.99785763\n",
      "  -0.99197954  0.99999815 -0.9999999  -0.1334543   1.         -0.99961054\n",
      "   0.9971871  -0.9864564   0.16868946 -0.9927629   0.99999714  0.92002654\n",
      "  -0.9242947  -0.99993247  0.9988716  -0.97259384 -1.         -1.\n",
      "  -1.          0.9969333   0.9999597   0.9950434   0.8853871   0.9835156\n",
      "   0.99972886  0.99856824 -0.96492505 -0.9971054  -1.         -1.\n",
      "  -0.8998266  -0.93112665 -0.97404075  0.25372395 -1.         -0.91917866\n",
      "  -0.999935    0.9993159   1.         -1.          0.02619785 -0.9980975\n",
      "   0.99772954  1.         -1.          0.99999076  0.99244314  0.9997116\n",
      "  -1.          0.99882114 -0.50127333  1.         -0.9825593  -0.80438644\n",
      "   0.9998081  -0.6294048  -0.99988675 -0.97061986  0.9978046  -0.60766214\n",
      "  -1.          1.         -0.9982328   0.9995839  -0.86450356 -0.7621475\n",
      "  -0.99988246  0.9517748  -0.8212133   0.29458538 -0.99822944  1.\n",
      "   1.          0.9689294   0.9927623  -0.9999997  -0.99927294  1.\n",
      "  -0.99918365  0.8140406   0.6913409   0.9389424  -0.8062347   0.9999998\n",
      "   0.94318414 -0.9999073   0.98991054 -0.9620754  -0.2048677  -0.9984225\n",
      "  -0.3925023  -0.9938646   0.19343045  0.99784297  0.99148333  1.\n",
      "   1.         -0.9217595  -1.          0.77762693  0.9206416  -1.\n",
      "  -0.9989347  -0.46215376  0.99968785  0.8087304  -0.20582055  0.88348746\n",
      "   0.9997589   0.99866796 -0.99227613 -0.99996084  0.99986947 -0.82793546\n",
      "  -0.99841046 -0.99909645  0.98211884  1.         -0.99999994  0.99616045\n",
      "   0.99999976 -0.99999243 -0.9999997  -0.99999714  1.          0.9939314\n",
      "   0.9915205   0.99771667 -0.99999744  1.          0.98841125 -1.\n",
      "  -0.9999999   0.992869    0.7338442  -1.         -0.99971646 -0.9977229\n",
      "   1.          0.9964064  -0.99997866  0.95792246  0.99862623 -0.95916855\n",
      "  -0.93258077  1.          0.9999815  -0.99965525 -0.05712371  0.7929299\n",
      "   1.         -1.         -0.6329475   0.99999905  0.9999928  -0.91384923\n",
      "  -0.58143145 -0.9999974  -0.5022543  -0.9884215   0.624604    0.99521846\n",
      "  -0.9662708   0.99879575  0.9193487   0.865709   -0.7023985   0.99981546\n",
      "   1.          0.9362286   0.8811558  -0.8053179  -0.52614635  0.9999964\n",
      "   0.715626    0.65080994 -1.          0.9999999   0.97201806  0.08371986\n",
      "  -0.95372385 -0.98426545  0.80217105 -0.99989295  0.13942531  0.9476909\n",
      "   0.33133063  0.9190514  -0.6456253  -0.99998987  1.          1.\n",
      "   0.9996623   1.          0.98093593  0.95855576 -0.999997   -0.9999968\n",
      "  -0.7713579  -0.32009804 -1.         -0.8165566  -0.9010421  -0.9143436\n",
      "   0.9901418  -0.9999998   0.99999607 -0.9999999  -0.998353   -0.7945884\n",
      "  -1.          0.9976139  -0.9991723   0.99999976  0.99764085 -0.904344\n",
      "  -0.7195365   0.39754888  0.9692617   0.99999946  0.7809415   0.99996835\n",
      "   0.2042065   0.94715154  1.         -0.9319129  -1.          0.9995099\n",
      "   0.04715452 -0.9994818  -0.42997733  1.          0.99354106 -0.9204685\n",
      "  -1.         -0.9998621   0.9452658  -1.         -0.930602   -0.96134114\n",
      "   0.9231319  -1.          0.998021   -1.         -0.9650018  -0.9998429\n",
      "   0.9979359   0.9999817  -1.          1.          0.99999255 -0.6386368\n",
      "   0.9985998  -0.99998945  0.9899824   0.99999994 -0.999888   -0.99999803\n",
      "  -0.8187794   0.9694751  -1.         -0.9999899  -0.99989164 -0.9997336\n",
      "   0.71843225 -0.9999976  -0.99996877 -0.24212894 -0.9999994   0.8264482\n",
      "   1.          0.9999992  -0.99702954  0.9999466   0.44653472  0.9999996\n",
      "   0.90473604  0.9982967   0.5623085   1.         -1.         -0.9999001\n",
      "   0.9843751  -1.         -0.99825895  1.         -0.99998593 -0.9999754\n",
      "   0.9998784   1.         -0.9999596   0.9449999  -0.23792729 -0.87703335\n",
      "  -1.         -0.98388255 -0.9954633  -1.          0.9526344  -0.9994247\n",
      "  -0.9998663  -0.9999824   0.99923533  0.99523705  0.79224306  0.8937728\n",
      "  -0.9999904  -0.99992746  0.96328104  0.9943542   0.99419624 -0.9999978\n",
      "   1.         -0.9974183   0.99996316 -0.29180914  0.99776316  0.98274726\n",
      "   0.9976778   1.          0.9008968   0.2652352  -0.9936546   1.\n",
      "  -0.9140652  -1.          0.98997015 -0.9999998  -1.          0.9895605\n",
      "   0.9878826   0.9973655  -0.9962906  -0.9982992   0.17212194 -0.99960595\n",
      "   0.05793662 -1.          0.99999964  0.9912048  -1.         -0.9885665\n",
      "  -0.99027854 -0.75728613  0.9975246  -0.17518283 -0.99129784 -0.99999326\n",
      "   0.99997216 -0.99999934 -0.8279135   0.98660266  0.99603254 -0.6756388\n",
      "  -0.73366576  1.          1.         -0.9998628   0.8316435  -0.36663297\n",
      "   0.6111818   0.9988032   0.9810425  -0.9588537   0.99946827  0.9999987\n",
      "  -0.99960554  0.96805835  0.10139566 -1.         -0.99993324  0.5664535\n",
      "   0.99999994 -0.9979602  -0.9999974   0.9998277  -0.99928087 -0.9969642\n",
      "   0.9999832  -0.9999965   1.          1.         -0.94715965 -0.99986416\n",
      "   0.99730986  1.          0.9552287   0.9998091   0.99668235  0.99999964\n",
      "   1.         -0.99133563 -0.99994016  1.          0.92216295  0.9958406\n",
      "   0.98467463 -0.9994917   0.94751585  0.9999906   0.98752344  0.9999849\n",
      "  -0.9970721  -1.          0.06024257  0.9171032  -0.999989    1.\n",
      "   0.9999998  -0.7093232   0.99872464  0.9995062   0.3213703   0.93169993\n",
      "   1.         -0.9996941   0.9998097  -0.9960458   0.9174445   0.9999964\n",
      "   0.999698   -0.985485   -0.99755925  0.8840505  -0.92540926 -0.99934196\n",
      "  -0.812333    0.9076929  -0.99119806  0.50136054  0.99026984 -0.9805378\n",
      "  -0.9999451   0.98480725  0.3855474  -0.55921125  0.99018514  0.8039649\n",
      "   1.         -1.         -0.9997191   0.80112714  0.6773006   0.995455\n",
      "   0.99996954  0.9993313   0.00101741 -0.9999991   0.99610806 -0.9970495\n",
      "   0.99996704 -0.99999976 -1.          0.99973965  0.9851188   0.9999948\n",
      "   1.          0.99614286  0.99999726  0.9982908  -0.7917841   0.99584585\n",
      "  -0.9914651  -1.          0.9999999   1.          0.999995    0.14218165\n",
      "   0.990493   -0.9999999  -0.9906783   0.99999744 -0.99533266  0.9892171\n",
      "   0.9384903   0.8418765   1.          0.999998    0.9800671   0.99886674\n",
      "   0.9999988   0.99946433  0.98491037  0.9996923  -0.794424   -0.99994105\n",
      "   0.9982707   1.         -0.05766923  0.9999987   0.817619    0.7983517\n",
      "  -0.14292373  1.         -0.99759513 -0.9999982  -0.9997338  -0.99937415]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('./pytorch-ernie')\n",
    "model = BertModel.from_pretrained('./pytorch-ernie')\n",
    "input_ids = torch.tensor([tokenizer.encode(\"hello world\", add_special_tokens=True)])\n",
    "with torch.no_grad():\n",
    "    sequence_output, pooled_output = model(input_ids)\n",
    "print(pooled_output.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
