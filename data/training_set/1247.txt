[]
人臉辨識系統有偏見 研究：有色人種誤判機率高
美國政府今天發布的研究指出，人臉辨識系統可能產生誤差非常大的結果，特別是非白種人臉孔。這項人工智慧技術的運用，可能引發新疑慮。
美國國家標準技術研究所（NIST）針對數十種臉部辨識演算法的研究報告顯示，辨識亞裔和非裔美國人臉孔的「偽陽性」率比白種人高100倍。美國國家標準技術研究所是政府研究機構。
美國國家標準技術研究所研究人員也發現，其中兩個演算法誤認非裔女性性別的機率將近35%。
人臉辨識系統廣泛運用在執法單位、機場、邊境管制、銀行、商家和學校，以及像是解鎖智慧型手機等個人科技。
某些倡議人士和研究人員宣稱，人臉辨識的潛在錯誤層出不窮，而這些錯誤可能導致無辜民眾入獄。另外，這項科技若被用來建立成資料庫，可能被駭或被不當使用。
首席研究員葛羅勒（Patrick Grother）說：「偽陰性可能僅會造成不便，你無法解鎖手機，但通常試了第2次就能補救。但在一對多搜尋中出現偽陽性，不正確比對結果會被列入名單中，有必要進行進一步檢視。」