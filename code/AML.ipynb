{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Clone the repo to your local machine using https://github.com/NadalChi/AML.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AML'...\n",
      "remote: Enumerating objects: 4900, done.\u001b[K\n",
      "remote: Counting objects: 100% (4900/4900), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4785/4785), done.\u001b[K\n",
      "remote: Total 4900 (delta 63), reused 4879 (delta 49), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (4900/4900), 7.04 MiB | 2.59 MiB/s, done.\n",
      "Resolving deltas: 100% (63/63), done.\n",
      "Updating files: 100% (5036/5036), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NadalChi/AML.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model\n",
    "Install this package first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googledrivedownloader in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install googledrivedownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under folder /code, run the following command. Or just run download_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/huangchingchi/Desktop/AML/code/AML/code\n",
      " == Download model == \n",
      "Downloading 1pC9OGFrsV4l_JCUT5Mn6eZgZXsDxFL8a into ../model/finetuned_token_cls_model... Done.\n",
      " == Done == \n"
     ]
    }
   ],
   "source": [
    "%cd AML/code\n",
    "%run -i 'download_model.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data\n",
    "Load sample data from data set.  \n",
    "You can choose any data you want between 1.txt to 5023.txt.  \n",
    "For example, if you want to load single data set 10.txt, then you can call function as `aml.load_smaple_data(10)`.  \n",
    "The implement result shows as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      " 40歲楊姓女子因缺錢花用，今年6月間帶著安姓小妹、陳姓小弟到清水區一家檳榔攤，楊女先持玩具槍喝令店員「不准動」，並由安女負責搜刮店內財物、陳男則負責把風，事後3人被捕，陳男雖辯稱「是被逼迫犯案」，仍被依強盜罪起訴。起訴指出，今年6月2日清晨，楊姓女子帶著陳姓小弟（39歲），先在彰化縣中正路附近強盜一部小轎車，之後由陳男負責駕車、載著楊女到台中市西屯區接安姓女子（26歲），接著3人共乘1車，沿途尋找犯案目標，行經清水區一家檳榔攤前時，便決定下手。手持玩具槍的楊女與安女先下車進入檳榔攤，由楊女持槍恐嚇店員「別動」，安女則進入拿走檳榔攤內現金共8300元，緊接著，楊女離去前還取走店內11包香菸，而整個過程，陳男都負責在車上把風、接應。警方事後獲報並逮獲3人，楊女坦承犯案，而安女、陳男都辯稱「是受楊女逼迫」，且陳男還供稱「事前因為有吃藥，根本記不得過程，只記得有開車、都是聽楊女指示」。台中檢方認為，楊女雖是主導，但陳男、安女明顯有自主意識，卻未趁機離開、還善盡把風之責，明顯是共犯，依強盜罪起訴3人。違反上述規定者，中時電子報有權刪除留言，或者直接封鎖帳號！請使用者在發言前，務必先閱讀留言板規則，謝謝配合。\n",
      "['林繼蘇', '徐詩彥']\n",
      " 為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Microsoft Edge 的瀏覽器。〔記者吳昇儒／基隆報導〕男子林繼蘇與前跆拳道國手徐詩彥利用買賣水產的名義，對外吸金超過19億，檢警偵辦時，兩人互相卸責，林男自稱只是投資人，提供支票、帳戶給徐女使用。檢察官卻查出雙方有多筆金流往來，涉案情節重大，依法將他起訴。基隆地方法院近日偵結，依違反銀行法判處林男有期徒刑8年半。檢警調查，開設補習班的徐女於2014年起利用從事水產小額團購等方式，向學生家長及友人推銷水產進口投資方式，吸引多人參加，其中分為臨時單與固定單，佯稱可以獲得年息最高可獲得180%，讓投資人趨之若鶩，捧著大批資金投資；後來因投資額逐漸增加，徐女便找來可以開立支票的林男一起參與。林男則提供帳戶及支票，讓徐女運轉使用，投資人則將投資資金匯入林男的戶頭內，直到後來發現，帳戶內的餘額已不夠支付支票費用，因而跳票，案件也因此曝光。林男偵訊時向法官辯稱，自己的小孩在徐女教學的補習班補習，雙方曾有借貸關係，後來徐女邀自己投資，才會出借支票及帳戶，匯進帳戶的錢說是投資廠商，並不知道他們是誰，自己只是借票給徐女使用的投資者而已。徐女則向法官表示，當時是林男說他有朋友在做水產貨櫃投資，說利潤不錯，所以才介紹朋友投資。檢警調查徐女吸金時也發現，徐女所支付給投資人的支票，多為都是林男開立，且投資款項大部分都是匯入林男設立著帳戶內，若林男單純只是投資者，不可能冒那麼大的風險。法官認為，林男自稱是投資徐女水產貨櫃生意，但事後卻將戶頭裡面的錢轉到支票帳戶內，不可能不知道自己戶頭內的資金如何應用，且這些年來開立支票金額高達十多億元，若不知徐女意圖，怎麼可能貿然開出。法官認定，林男行為已經觸犯銀行法，且金額超過億元，依違反非法經營收受存款業務罪判處他有期徒刑8年半；未扣案的共同犯罪所得3億1740萬1千元，除應發還被害人獲得請求損害賠償之人外，應與徐詩彥共同沒收之，不能或不宜執行沒收時，追徵其價額。徐女一、二審被重判12年半，經再次上訴後，更一審於今年5月判處她有期徒刑9年半，減少3年刑期。\n"
     ]
    }
   ],
   "source": [
    "import AML_readme as aml\n",
    "label, text = aml.load_smaple_data(4801)\n",
    "print(label, text)\n",
    "label, text = aml.load_smaple_data(4802)\n",
    "print(label, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data\n",
    "As we have the sample data and the lables. We have to convert each word in sample data to token.  \n",
    "And give each word a lable. What we are doing is classification. If the word belongs to AML-related focal persons. We set the label to one else we set it to zero.  \n",
    "The implement result shows as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([ 101,  711, 6809, 3297,  881, 3846, 6222, 3126, 3362, 8024, 2456, 6379,\n",
      "         886, 4500,  510, 2772, 4638, 3846, 6222, 1690,  526, 6381, 5442, 1426,\n",
      "        1285, 1027, 8027, 1825, 7384, 2845, 2193,  527, 4511, 2094, 3360, 5326,\n",
      "        5722,  680, 1184, 6647, 2891, 6887, 1744, 2797, 2528, 6408, 2503, 1164,\n",
      "        4500,  743, 1297, 3717,  772, 4638, 1399,  721, 8024, 2190, 1912, 1429,\n",
      "        7032, 6631, 6814,  783, 8024, 3466, 6356,  903, 1215, 3198, 8024,  697,\n",
      "         782,  757, 4685, 1319, 6569, 8024, 3360, 4511, 5632, 4917, 1372, 3221,\n",
      "        2832, 6598,  782, 8024, 2990,  897, 3118, 4873,  510, 2362, 2787, 5314,\n",
      "        2528, 1957,  886, 4500, 3466, 2175, 2135, 1316, 3389, 1139, 1352, 3175,\n",
      "        3300, 1914, 5011, 7032, 3837, 2518, 3341, 8024, 3868, 3428, 2658, 5688,\n",
      "        7028, 1920, 8024,  898, 3791, 2199,  800, 6629, 6401, 1825, 7384, 1765,\n",
      "        3175, 3791, 7368, 6818, 3189,  903, 5310, 8024,  898, 6824, 1353, 7213,\n",
      "        6121, 3791, 1161, 1905, 3360, 4511, 3300, 3309, 2530, 1152, 2399, 1288,\n",
      "        3466, 6356, 6444, 3389, 8024, 2458, 6392, 6133,  739, 4408, 4638, 2528,\n",
      "        1957,  754, 2399, 6629, 1164, 4500,  794,  752, 3717,  772, 2207, 7583,\n",
      "        1730, 6579, 5023, 3175, 2466, 8024, 1403, 2110, 4495, 2157, 7270, 1350,\n",
      "        1351,  782, 2972, 7218, 3717,  772, 6822, 1366, 2832, 6598, 3175, 2466,\n",
      "        8024, 1429, 2471, 1914,  782, 1346, 1217, 8024, 1071,  704, 1146,  711,\n",
      "         707, 3198, 1296,  680, 1743, 2137, 1296, 8024,  879, 4917, 1377,  809,\n",
      "        5815, 2533, 2399, 2622, 3297, 7770, 1377, 5815, 2533, 8024, 6375, 2832,\n",
      "        6598,  782, 6633,  722, 5735, 7909, 8024, 2942, 4708, 1920, 2821, 6598,\n",
      "        7032, 2832, 6598, 8039, 1400, 3341, 1728, 2832, 6598, 7583, 6852, 3933,\n",
      "        1872, 1217, 8024, 2528, 1957,  912, 2823, 3341, 1377,  809, 2458, 4989,\n",
      "        3118, 4873, 4638, 3360, 4511,  671, 6629, 1346,  680, 3360, 4511, 1156,\n",
      "        2990,  897, 2362, 2787, 1350, 3118, 4873, 8024, 6375, 2528, 1957, 6817,\n",
      "        6760,  886, 4500, 8024, 2832, 6598,  782, 1156, 2199, 2832, 6598, 6598,\n",
      "        7032, 3726, 1057, 3360, 4511, 4638, 2787, 1928, 1079, 8024, 4684, 1168,\n",
      "        1400, 3341, 1355, 4385, 8024, 2362, 2787, 1079, 4638,  865, 7583, 2347,\n",
      "         679, 1916, 3118,  802, 3118, 4873, 6589, 4500, 8024, 1728, 5445, 6663,\n",
      "        4873, 8024, 3428,  816,  738, 1728, 3634, 3284, 1045, 3360, 4511,  903,\n",
      "        6380, 3198, 1403, 3791, 2135, 6796, 4917, 8024, 5632, 2346, 4638, 2207,\n",
      "        2111, 1762, 2528, 1957, 3136, 2110, 4638, 6133,  739, 4408, 6133,  739,\n",
      "        8024, 1352, 3175, 3295, 3300,  955, 6587, 1068, 5143, 8024, 1400, 3341,\n",
      "        2528, 1957, 6913, 5632, 2346, 2832, 6598, 8024, 2798,  833, 1139,  955,\n",
      "        3118, 4873, 1350, 2362, 2787, 8024, 3726, 6822, 2362, 2787, 4638, 7178,\n",
      "        6432, 3221, 2832, 6598, 1322, 1555, 8024, 2400,  679, 4761, 6887,  800,\n",
      "         812, 3221, 6443, 8024, 5632, 2346, 1372, 3221,  955, 4873, 5314, 2528,\n",
      "        1957,  886, 4500, 4638, 2832, 6598, 5442, 5445, 2347, 2528, 1957, 1156,\n",
      "        1403, 3791, 2135, 6134, 4850, 8024, 2496, 3198, 3221, 3360, 4511, 6432,\n",
      "         800, 3300, 3301, 1351, 1762,  976, 3717,  772, 6573, 3385, 2832, 6598,\n",
      "        8024, 6432, 1164, 3883,  679, 7231, 8024, 2792,  809, 2798,  792, 5305,\n",
      "        3301, 1351, 2832, 6598,  102]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), (tensor([ 101, 3466, 6356, 6444, 3389, 2528, 1957, 1429, 7032, 3198,  738, 1355,\n",
      "        4385, 8024, 2528, 1957, 2792, 3118,  802, 5314, 2832, 6598,  782, 4638,\n",
      "        3118, 4873, 8024, 1914,  711, 6963, 3221, 3360, 4511, 2458, 4989, 8024,\n",
      "         684, 2832, 6598, 3621, 7555, 1920, 6956, 1146, 6963, 3221, 3726, 1057,\n",
      "        3360, 4511, 6392, 4989, 4708, 2362, 2787, 1079, 8024, 5735, 3360, 4511,\n",
      "        1296, 5283, 1372, 3221, 2832, 6598, 5442, 8024,  679, 1377, 5543, 1088,\n",
      "        6929,  720, 1920, 4638, 7599, 7372, 3791, 2135, 6371,  711, 8024, 3360,\n",
      "        4511, 5632, 4917, 3221, 2832, 6598, 2528, 1957, 3717,  772, 6573, 3385,\n",
      "        4495, 2692, 8024,  852,  752, 1400, 1316, 2199, 2787, 1928, 7027, 7481,\n",
      "        4638, 7178, 6760, 1168, 3118, 4873, 2362, 2787, 1079, 8024,  679, 1377,\n",
      "        5543,  679, 4761, 6887, 5632, 2346, 2787, 1928, 1079, 4638, 6598, 7032,\n",
      "        1963,  862, 2418, 4500, 8024,  684, 6821,  763, 2399, 3341, 2458, 4989,\n",
      "        3118, 4873, 7032, 7583, 7770, 6809, 1282, 1914,  783, 1039, 8024, 5735,\n",
      "         679, 4761, 2528, 1957, 2692, 1745, 8024, 2582,  720, 1377, 5543, 6588,\n",
      "        4197, 2458, 1139, 3791, 2135, 6371, 2137, 8024, 3360, 4511, 6121,  711,\n",
      "        2347, 5307, 6239, 4306, 7213, 6121, 3791, 8024,  684, 7032, 7583, 6631,\n",
      "        6814,  783, 1039, 8024,  898, 6824, 1353, 7478, 3791, 5307, 5852, 3119,\n",
      "        1358, 2100, 3621,  689, 1218, 5389, 1161, 1905,  800, 3300, 3309, 2530,\n",
      "        1152, 2399, 1288, 8039, 3313, 2807, 3428, 4638, 1066, 1398, 4306, 5389,\n",
      "        2792, 2533,  783,  674, 1283, 1039, 8024, 7370, 2418, 1355, 6820, 6158,\n",
      "        2154,  782, 5815, 2533, 6435, 3724, 2938, 2154, 6608,  985,  722,  782,\n",
      "        1912, 8024, 2418,  680, 2528, 6408, 2503, 1066, 1398, 3766, 3119,  722,\n",
      "        8024,  679, 5543, 2772,  679, 2139, 2809, 6121, 3766, 3119, 3198, 8024,\n",
      "        6841, 2519, 1071,  817, 7583, 2528, 1957,  671,  510,  753, 2144, 6158,\n",
      "        7028, 1161, 2399, 1288, 8024, 5307, 1086, 3613,  677, 6401, 1400, 8024,\n",
      "        3291,  671, 2144,  754,  791, 2399, 3299, 1161, 1905, 1961, 3300, 3309,\n",
      "        2530, 1152, 2399, 1288, 8024, 1121, 2208, 2399, 1152, 3309,  102]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))]\n"
     ]
    }
   ],
   "source": [
    "tokens = aml.process_data(label, text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Create training set and validation set.  \n",
    "The model will saved under folder '~/model'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aml.load_processed_data(1, 4000)\n",
    "validset = aml.load_processed_data(4000, 5024)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "trainloader = aml.DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=aml.create_mini_batch)\n",
    "validloader = aml.DataLoader(validset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=aml.create_mini_batch)\n",
    "EPOCHS = 30\n",
    "aml.train(trainloader, validloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "The model we provide was trained by using 1.txt to 4000.txt from data set.  \n",
    "Load the model we downloaded at begin. The path was set equal to '../model/finetuned_token_cls_model'.  \n",
    "You can also load the path where your model at.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = aml.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "If you are doing inference. First argument is the article you are going to inference. Second argument is the model you loaded.  \n",
    "The inference result shows as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = aml.load_smaple_data(4801)[1]\n",
    "aml.inference(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['林繼蘇', '徐詩彥']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = aml.load_smaple_data(4802)[1]\n",
    "aml.inference(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
